+++
title = "AI 绘画的现状、入口、困难和展望"
date = 2022-08-30

[taxonomies]
categories = ["小妙招"]
tags = ["software"]
+++


# AI 绘画的现状、入口、困难和我的展望  
>***目录***   
>1.现状  
>2.暂时做不到但可能很快能做到的，以及暂时不知道怎么做的。   
>3.视觉和设计从业者如何有效使用 AI 做辅助（或者为 AI 做辅助）  
>4.结语。

## 第一部分：现状。  

AI 绘画此刻正在以前所未有的速度爆发性增长。很少有机会目睹一个领域里新的产品会忽然像雨后春笋一样不断涌现，每个月甚至每一天都在进步，你上个月对这个领域形成的印象可能现在已经过时了。一个标志性的事件是本周一 Stable Diffusion 宣布开源——不仅仅是程序，包括训练好的模型也开源。它是目前水平最高的绘画 AI 之一，它的开源意味着可以预期接下来会有很多包装 stable fusion 内核的产品出现，这是一个指数型增长的前夜。

目前最好的绘画 AI 大致有下面这些：

普通人可以用的：

- Stable Diffusion 可以直接在[网页链接](https://beta.dreamstudio.ai/) 试用，不需要排队，但有免费额度限制，额度用完后可以购买。普通人推荐首先试用这个。

- Dall-E 2 申请免费试用需要排队，可以直接在 [网页链接](https://www.craiyon.com/) 玩一个网页版，但很慢。

- MidJourney 需要有 Discord 账号才能试用，[微博教程](https://weibo.com/ttarticle/p/show?id=2309404791427086549206#_0)

- 百度 文心·一格 [网页链接](https://yige.baidu.com/#/) 申请免费试用需要排队

MidJourney，Dall-E 2 和 Stable Diffusion 基本上是目前公认效果最好的三个 AI。推上有人做了一个非常好玩的对比 [网页链接](https://twitter.com/fabianstelzer/status/1561019187451011074) ，用同样的提示词给三个 AI 让它们同时出图，放在一起，风格区别一目了然，很像美术课考试。

已发表但还并未开放给普通用户的：
- 来自谷歌的 Parti 
- 来自微软的女娲 
- 来自脸书的 Make-A-Scene

以上不是完全名单。@Simon_阿文 这里有更长的一个单子：[微博正文 ](https://weibo.com/1757693565/LxI61mlLk)

如果是完全不懂任何技术的小白，只想试着玩一下，上面给出的 Stable Diffusion 试用版可能是最简单的入口。需要说明的是，要获得比较好的效果，你给的提示词越详细越好。这是目前绘画 AI 的一个特点（也可以说是缺点，目前大多数 AI 都有这个问题）：你只提示一两个主题词，效果就乏善可陈，但如果比方输入 portrait of Zelda, robot steampunk, floral, intricate, elegant, highly detailed, ray tracing, digital painting, concept art, smooth, sharp focus, illustration, Mucha, HQ 这样长长一大串，效果就会好很多。提示词不需要是一个句子，一堆词组放在一起就可以。

如果懂一点技术，知道神经网络 model 大概是怎么回事，会用 google colab，有 hugging face 账号，那可以走专业一点的入口通道。Dall-E 的 model card: [网页链接](https://huggingface.co/dalle-mini/dalle-mini) Stable Fusion 的 model card：[网页链接 ](https://huggingface.co/CompVis/stable-diffusion)甚至可以直接在 google colab 里跑 Stable Diffusion：[网页链接](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)

如果会用 Python 安装脚本，有自己的显卡，你还可以直接在本地机上跑 Stable Diffusion 模型，这里有一个非常清晰的指南：[网页链接](https://www.assemblyai.com/blog/how-to-run-stable-diffusion-locally-to-generate-images/) 从如何设置 conda 环境到如何下载已经训练好的模型都有说明。自己运行模型意味着可以玩一些复杂功能，比如输入一个简笔画，让 AI 生成一个复杂的图片。


## 第二部分：暂时做不到但可能很快能做到的，以及暂时不知道怎么做的。

AI 暂时做不到或者做不好的事情主要是在下面这几个方面：

1. 目前 AI 理解提示词以风格和内容描述为主，比如这幅画包含什么东西，是哪位艺术家的风格等等。一旦牵涉到语义逻辑就困难一些，比如「窗前有一个桌子，桌子上有两个盘子，盘子里没有香蕉只有苹果」这种描述。Google 的 Parti 号称在这一点上更好，但因为还没有开放公测，无法验证是否如此。目前开放的几个 AI 在这一点表现都不佳。
这在理论上本身是个有点麻烦的问题，牵涉到自然语言理解，所以只有伴随着自然语言人工智能模型一道进步。

2. AI 不理解空间和物理。比方说几乎所有的 AI 都画不好镜子，因为镜子内外的图像需要用到光学知识，而 AI 模型是基于统计的，不懂光学。类似的，AI 的透视学的很糟，一个典型的例子是你会发现 AI 画的轮子都不太圆，AI 首先不知道「轮子必须非常圆才能转动」这个人类生活常识，其次也不知道侧面看圆应该压扁到什么程度才合理。另一个例子是 AI 画的透明玻璃酒杯细节上都不太对。
这一条在理论上也有点困难，目前没有特别好的解决方案。

3. AI 做不到内容统一性。比如你觉得 AI 某一张人像画的很好，你无法对它说：再画一张同一个人，穿同样的衣服，但让头转过来一点。—— AI 不理解什么是「同一个人」，甚至也不理解什么是「同一件衣服」。这听起来有点荒谬，因为在别的领域里（比如摄像头人脸识别）AI 分明很擅长判断是不是同一张人脸，但绘画的 AI 并没有内置这个逻辑。这导致了一个问题：AI 画画是一张张彼此无关的，你很难让它画成套的作品，比如一个有故事性的有复杂人物关系的连环画。
这个在理论上解决起来有希望，但并不容易，预期在一年内可以有进展。现在有一些这样的尝试，譬如 [微博正文](https://weibo.com/1986967605/M2AUpuLQ9)，但很初级。

4. AI 不会画文字，因为 AI 不识字……
这倒不是什么理论上的困难问题，单纯是个软件工程上的挑战。可能很快就可以解决了。

## 第三部分：视觉和设计从业者如何有效使用 AI 做辅助（或者为 AI 做辅助）

根据 AI 目前的特长来看，直接生成全图是个有趣但很快就会玩腻的事，因为人对最终的成图没有什么控制，只能挑挑拣拣。更好的使用方式可能是让人负责打出大的框架，让 AI 来填充细节。

AI 在绘制纹理和材质质感上非常出色，笔触和技法一流，但越宏观的能力越弱。目前这样的工作流还不够傻瓜化，但我相信在接下来的几个月里会有大量应用涌现出来。

一个此刻就能采用的工作思路是让 AI 生成图像的「组分」，比如一只蝴蝶，一片草坪，一桩大楼，一个机器人，然后人把它拼接起来。推特上的 NekroXIII [一个例子](https://twitter.com/NekroXIII/status/1558724005112303617)

另一个已经存在的工作场景是针对设计师的：可以用 AI 为 Figma 这类工具做插件，使得设计师只需要画出寥寥几笔，AI 就可以渲染出细节。例如左边是输入，右边是输出。这个插件叫 Ando，作者是 Antonio Cao [网页链接](https://twitter.com/RemitNotPaucity/status/1562319004563173376)

AI 也可以和 3D 渲染工具结合在一起，比如 Blender。微博上的 @Simon_阿文 对此就有介绍：[微博正文](https://weibo.com/1757693565/LuludENdd)

当然还有最简单的方法：让 AI 提供设计灵感，比如服装设计。一个日本创作者用 MidJourney 画的日本神道服饰：[网页链接](https://twitter.com/midyznk/status/1558144979532271621) 注意文字都是 AI 瞎写的。

## 结语
一个有趣的科研进展：目前最好的 AI 模型是 diffusion model，在过去一年里一举取代了之前被广泛采用的 GAN 和 VAE。Diffusion model 的数学原理有点复杂，建立于朗之万扩散模型之上，这使得所有 diffusion model 的论文读起来都很累人。但马里兰大学的 Tom Goldstein 前几天发了一条推 [网页链接](https://twitter.com/tomgoldsteincs/status/1562503814422630406) 指出：目前所有这些关于 diffusion model 数学理解都是错的。细节在这里不展开了，但他的这个发现在我看来非常有说服力。很可能一些理论上的新突破还在前面。
